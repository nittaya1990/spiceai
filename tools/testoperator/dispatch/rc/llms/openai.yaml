tests:
  http_consistency:
    spicepod_path: ./test/spicepods/models/openai.yaml
    concurrency: 8
    duration: 3600
    payload_file: ./test/payloads/model-generic-lorem.txt
    model: gpt-4o-mini
    ready_wait: 0
    buckets: 60
  http_overhead:
    spicepod_path: ./test/spicepods/models/openai.yaml
    concurrency: 8
    duration: 3600
    payload_file: ./test/payloads/model-generic-lorem.txt
    model: gpt-4o-mini
    warmup: 0
    base: openai
    base_component: gpt-4o-mini
